{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dotenv\n",
    "# pip install anthropic\n",
    "# pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a member of an automated AI software engineering team. You will be asked to write code in various programming languages including Python, Swift, Javascript, and more.\n",
      "- Use proper naming conventions for the programming language. \n",
      "- Always follow SOLID principles of programming.\n",
      "- Write the minimum lines of code required to effectively accomplish your task, without sacrificing code readability.\n",
      "\n",
      "Extensions by language:\n",
      "  - Python = py\n",
      "  - Javascript = js\n",
      "  - Swift = swift\n",
      "\n",
      "Your response will be parsed and used to create a file in the local directory, so it is crucial that you respond in the proper format.\n",
      "Use level two headers (##) to indicate the file path (including the extension). Immediately follow it with a codeblock containing the content of the file.\n",
      "\n",
      "<ResponseFormat>\n",
      " ## path/to/file.extension\n",
      "```extension\n",
      "[Your code here]\n",
      "```\n",
      "</ResponseFormat>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from onyx import get_logger\n",
    "from pathlib import Path\n",
    "import re\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "from onyx.rate_limiter import RateLimiter\n",
    "from onyx.api_error_handler import ApiErrorHandler\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "PROMPTS_DIR = Path(\"./prompts\")\n",
    "\n",
    "def get_prompt_and_system(prompt_name: str, **kwargs) -> tuple[str, str]:\n",
    "    \"\"\"Get both the system prompt and formatted user prompt as a tuple.\"\"\"\n",
    "    prompt_path = PROMPTS_DIR / f\"{prompt_name}.yaml\"\n",
    "    if not prompt_path.exists():\n",
    "        logger.error(f\"Prompt file not found: {prompt_path}\")\n",
    "        raise FileNotFoundError(f\"Prompt file not found: {prompt_path}\")\n",
    "\n",
    "    with open(prompt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        prompt_config = yaml.safe_load(file)\n",
    "\n",
    "    system_prompt = prompt_config.get(\"system_prompt\", \"\")\n",
    "    template = prompt_config.get(\"prompt_template\", \"\")\n",
    "\n",
    "    try:\n",
    "        formatted_prompt = template.format(**kwargs)\n",
    "        return system_prompt, formatted_prompt\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Missing required parameter in prompt {prompt_name}: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error formatting prompt {prompt_name}: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_code_from_md(markdown: str, language: str, output_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Extract and save code blocks from markdown into project_dir / app_name / relative_path.language.\n",
    "\n",
    "    Args:\n",
    "        markdown: The original markdown content\n",
    "        language: The language to extract from code blocks. Not case sensitive - lowercase enforced.\n",
    "        output_dir: The parent directory that files and directories should be saved to.\n",
    "    \"\"\"\n",
    "    sections = re.split(r\"^##\\s+\", markdown, flags=re.MULTILINE)\n",
    "    code_pattern = re.compile(\n",
    "        rf\"```{re.escape(language.lower())}\\s*(.*?)```\", re.DOTALL\n",
    "    )\n",
    "    count = 0\n",
    "    for section in sections[1:]:\n",
    "        lines = section.strip().split(\"\\n\", 1)\n",
    "        if len(lines) < 2:\n",
    "            continue\n",
    "        rel_path, body = lines[0].lstrip(\"/\"), lines[1]\n",
    "        match = code_pattern.search(body)\n",
    "        if not match:\n",
    "            continue\n",
    "        file_path = output_dir / rel_path\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        file_path.write_text(match.group(1).strip(), encoding=\"utf-8\")\n",
    "        count += 1\n",
    "    logger.info(f\"Parsed and saved {count} code blocks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _send_prompt(\n",
    "    prompt: str,\n",
    "    system_prompt: str,\n",
    "    temp: float = 0,\n",
    "    thinking_enabled: bool = False\n",
    ") -> str:\n",
    "    \"\"\"Send a prompt to Claude with retry logic for rate limits and other errors.\"\"\"\n",
    "    load_dotenv(override=True)\n",
    "    response = \"\"\n",
    "\n",
    "    \n",
    "    if thinking_enabled:\n",
    "        thinking_obj = {\"type\": \"enabled\", \"budget_tokens\": 24000}\n",
    "        temp = 1\n",
    "    else:\n",
    "        thinking_obj = {\"type\": \"disabled\"}\n",
    "\n",
    "    try:\n",
    "        with Anthropic().messages.stream(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=128000,\n",
    "            temperature=temp,\n",
    "            thinking=thinking_obj,\n",
    "            system=system_prompt,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            extra_headers={\"anthropic-beta\": \"output-128k-2025-02-19\"},\n",
    "        ) as stream:\n",
    "            for chunk in stream:\n",
    "                if hasattr(chunk, \"type\"):\n",
    "                    if chunk.type == \"text\":\n",
    "                        response += chunk.text\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in Claude API request: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "rate_limiter = RateLimiter(\n",
    "    requests_per_minute=3, token_limit_per_minute=16000\n",
    ")\n",
    "error_handler = ApiErrorHandler(max_retries=5, base_wait=5, max_wait=120)\n",
    "\n",
    "send_prompt = rate_limiter.with_rate_limiting(\n",
    "    error_handler.with_retries(_send_prompt)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">INFO    </span> Parsed and saved <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> code blocks                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mINFO    \u001b[0m Parsed and saved \u001b[1;36m1\u001b[0m code blocks                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## christmas_tree.py\n",
      "```python\n",
      "def draw_christmas_tree(height):\n",
      "    \"\"\"\n",
      "    Draws a Christmas tree in the console with the specified height.\n",
      "    \n",
      "    Args:\n",
      "        height (int): The height of the tree (number of rows for the tree part)\n",
      "    \"\"\"\n",
      "    # Draw the tree part\n",
      "    for i in range(height):\n",
      "        # Calculate spaces before the stars\n",
      "        spaces = height - i - 1\n",
      "        # Calculate number of stars for this row\n",
      "        stars = 2 * i + 1\n",
      "        \n",
      "        # Print the row\n",
      "        print(' ' * spaces + '*' * stars)\n",
      "    \n",
      "    # Draw the trunk (2 rows)\n",
      "    trunk_width = 3\n",
      "    trunk_spaces = height - trunk_width // 2 - 1\n",
      "    for _ in range(2):\n",
      "        print(' ' * trunk_spaces + '*' * trunk_width)\n",
      "    \n",
      "    # Draw the base\n",
      "    base_width = 5\n",
      "    base_spaces = height - base_width // 2 - 1\n",
      "    print(' ' * base_spaces + '*' * base_width)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # Get tree height from user\n",
      "    try:\n",
      "        height = int(input(\"Enter the height of the Christmas tree: \"))\n",
      "        if height < 3:\n",
      "            print(\"Height should be at least 3 for a nice tree.\")\n",
      "        else:\n",
      "            draw_christmas_tree(height)\n",
      "    except ValueError:\n",
      "        print(\"Please enter a valid number.\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "lang = \"python\"\n",
    "user_prompt = input(\"Enter prompt\") ## Opens input field at top of screen\n",
    "\n",
    "(system_prompt, prompt) = get_prompt_and_system(\n",
    "    prompt_name=\"coder\", language=lang, user_prompt=user_prompt\n",
    ")\n",
    "\n",
    "response = _send_prompt(\n",
    "    prompt=prompt,\n",
    "    system_prompt=system_prompt,\n",
    "    thinking_enabled=False,\n",
    ")\n",
    "\n",
    "save_code_from_md(response, lang, output_dir=Path(\"./\"))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
